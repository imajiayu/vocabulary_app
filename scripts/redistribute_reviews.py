# -*- coding: utf-8 -*-
"""
é‡æ–°åˆ†é…å•è¯å¤ä¹ æ—¥æœŸå’Œæ‹¼å†™æ—¥æœŸçš„è„šæœ¬

ä½¿ç”¨åœºæ™¯ï¼šé•¿æ—¶é—´æœªå¤ä¹ å¯¼è‡´å¤§é‡å•è¯å †ç§¯ï¼Œéœ€è¦é‡æ–°è§„åˆ’å¤ä¹ è®¡åˆ’

é…ç½®å‚æ•°ï¼š
- æ¯æ—¥å¤ä¹ ä¸Šé™ï¼šæ¯ä¸ª source 50ä¸ª
- æ¯æ—¥æ‹¼å†™ä¸Šé™ï¼šæ¯ä¸ª source 50ä¸ª
- æœ€å¤§åˆ†é…å¤©æ•°ï¼š90å¤©
- èµ·å§‹æ—¥æœŸï¼š2026-01-25

åˆ†é…ç­–ç•¥ï¼š
- æŒ‰ source åˆ†ç»„ï¼Œæ¯ä¸ª source ç‹¬ç«‹åˆ†é…
- å¤ä¹ ï¼šæŒ‰ ease_factor å‡åºæ’åˆ—ï¼ˆè¶Šä½è¶Šéš¾ï¼Œä¼˜å…ˆå¤ä¹ ï¼‰
- æ‹¼å†™ï¼šæŒ‰ spell_strength å‡åºæ’åˆ—ï¼ˆè¶Šä½è¶Šå¼±ï¼Œä¼˜å…ˆç»ƒä¹ ï¼‰
"""

import sys
import os
from datetime import date, timedelta
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.extensions import SessionLocal
from backend.models.word import Word

# ============ é…ç½®å‚æ•° ============
DAILY_REVIEW_LIMIT = 50  # æ¯ä¸ª source æ¯æ—¥å¤ä¹ ä¸Šé™
DAILY_SPELL_LIMIT = 50  # æ¯ä¸ª source æ¯æ—¥æ‹¼å†™ä¸Šé™
MAX_DAYS = 90  # æœ€å¤§åˆ†é…å¤©æ•°
START_DATE = date(2026, 1, 25)  # èµ·å§‹æ—¥æœŸ


def get_session():
    """åˆ›å»ºæ•°æ®åº“ä¼šè¯"""
    return SessionLocal()


def redistribute_review_dates(session, dry_run=True):
    """
    é‡æ–°åˆ†é…å¤ä¹ æ—¥æœŸ

    ç­–ç•¥ï¼šæŒ‰ source åˆ†ç»„ï¼Œæ¯ä¸ª source å†…æŒ‰ ease_factor å‡åºæ’åˆ—
    """
    # è·å–æ‰€æœ‰éœ€è¦å¤ä¹ çš„å•è¯
    words = (
        session.query(Word)
        .filter(Word.stop_review == 0)
        .filter(Word.ease_factor.isnot(None))
        .filter(Word.next_review.isnot(None))
        .order_by(Word.source, Word.ease_factor.asc())
        .all()
    )

    print(f"\nğŸ“š éœ€è¦é‡æ–°åˆ†é…å¤ä¹ æ—¥æœŸçš„å•è¯æ•°é‡: {len(words)}")

    if not words:
        print("æ²¡æœ‰éœ€è¦åˆ†é…çš„å•è¯")
        return []

    # æŒ‰ source åˆ†ç»„
    words_by_source = defaultdict(list)
    for word in words:
        words_by_source[word.source or "(æ— source)"].append(word)

    # ç»Ÿè®¡æ¯ä¸ª source
    print(f"\n   æŒ‰ source åˆ†ç»„ç»Ÿè®¡:")
    for source, source_words in sorted(words_by_source.items()):
        days_needed = (len(source_words) + DAILY_REVIEW_LIMIT - 1) // DAILY_REVIEW_LIMIT
        slots = DAILY_REVIEW_LIMIT * MAX_DAYS
        status = "âœ…" if len(source_words) <= slots else "âš ï¸"
        print(f"      {source}: {len(source_words)} ä¸ª â†’ éœ€è¦ {days_needed} å¤© {status}")

    # åˆ†é…æ—¥æœŸ
    changes = []
    date_counts = defaultdict(int)

    for source, source_words in words_by_source.items():
        for i, word in enumerate(source_words):
            day_offset = min(i // DAILY_REVIEW_LIMIT, MAX_DAYS - 1)
            new_date = START_DATE + timedelta(days=day_offset)

            if word.next_review != new_date:
                changes.append({
                    "word": word.word,
                    "source": word.source,
                    "old_date": word.next_review,
                    "new_date": new_date,
                    "ease_factor": word.ease_factor,
                })
                if not dry_run:
                    word.next_review = new_date

            date_counts[new_date] += 1

    # æ˜¾ç¤ºåˆ†é…ç»“æœç»Ÿè®¡
    print(f"\n   æ—¥æœŸåˆ†é…ç»Ÿè®¡ (å‰10å¤©ï¼Œæ‰€æœ‰ source åˆè®¡):")
    for i, (d, count) in enumerate(sorted(date_counts.items())[:10]):
        print(f"      {d}: {count} ä¸ªå•è¯")
    if len(date_counts) > 10:
        print(f"      ... å…± {len(date_counts)} å¤©")

    print(f"\n   éœ€è¦æ›´æ–°çš„å•è¯æ•°é‡: {len(changes)}")

    return changes


def redistribute_spell_dates(session, dry_run=True):
    """
    é‡æ–°åˆ†é…æ‹¼å†™æ—¥æœŸ

    ç­–ç•¥ï¼šæŒ‰ source åˆ†ç»„ï¼Œæ¯ä¸ª source å†…æŒ‰ spell_strength å‡åºæ’åˆ—
    """
    # è·å–æ‰€æœ‰éœ€è¦æ‹¼å†™ç»ƒä¹ çš„å•è¯
    words = (
        session.query(Word)
        .filter(Word.stop_review == 0)
        .filter(Word.spell_strength.isnot(None))
        .filter(Word.spell_next_review.isnot(None))
        .order_by(Word.source, Word.spell_strength.asc())
        .all()
    )

    print(f"\nâœï¸  éœ€è¦é‡æ–°åˆ†é…æ‹¼å†™æ—¥æœŸçš„å•è¯æ•°é‡: {len(words)}")

    if not words:
        print("æ²¡æœ‰éœ€è¦åˆ†é…çš„å•è¯")
        return []

    # æŒ‰ source åˆ†ç»„
    words_by_source = defaultdict(list)
    for word in words:
        words_by_source[word.source or "(æ— source)"].append(word)

    # ç»Ÿè®¡æ¯ä¸ª source
    print(f"\n   æŒ‰ source åˆ†ç»„ç»Ÿè®¡:")
    for source, source_words in sorted(words_by_source.items()):
        days_needed = (len(source_words) + DAILY_SPELL_LIMIT - 1) // DAILY_SPELL_LIMIT
        slots = DAILY_SPELL_LIMIT * MAX_DAYS
        status = "âœ…" if len(source_words) <= slots else "âš ï¸"
        print(f"      {source}: {len(source_words)} ä¸ª â†’ éœ€è¦ {days_needed} å¤© {status}")

    # åˆ†é…æ—¥æœŸ
    changes = []
    date_counts = defaultdict(int)

    for source, source_words in words_by_source.items():
        for i, word in enumerate(source_words):
            day_offset = min(i // DAILY_SPELL_LIMIT, MAX_DAYS - 1)
            new_date = START_DATE + timedelta(days=day_offset)

            if word.spell_next_review != new_date:
                changes.append({
                    "word": word.word,
                    "source": word.source,
                    "old_date": word.spell_next_review,
                    "new_date": new_date,
                    "spell_strength": word.spell_strength,
                })
                if not dry_run:
                    word.spell_next_review = new_date

            date_counts[new_date] += 1

    # æ˜¾ç¤ºåˆ†é…ç»“æœç»Ÿè®¡
    print(f"\n   æ—¥æœŸåˆ†é…ç»Ÿè®¡ (å‰10å¤©ï¼Œæ‰€æœ‰ source åˆè®¡):")
    for i, (d, count) in enumerate(sorted(date_counts.items())[:10]):
        print(f"      {d}: {count} ä¸ªå•è¯")
    if len(date_counts) > 10:
        print(f"      ... å…± {len(date_counts)} å¤©")

    print(f"\n   éœ€è¦æ›´æ–°çš„å•è¯æ•°é‡: {len(changes)}")

    return changes


def main():
    print("=" * 60)
    print("å•è¯å¤ä¹ æ—¥æœŸé‡æ–°åˆ†é…è„šæœ¬")
    print("=" * 60)
    print(f"\né…ç½®:")
    print(f"  - èµ·å§‹æ—¥æœŸ: {START_DATE}")
    print(f"  - æœ€å¤§åˆ†é…å¤©æ•°: {MAX_DAYS}")
    print(f"  - æ¯ä¸ª source æ¯æ—¥å¤ä¹ ä¸Šé™: {DAILY_REVIEW_LIMIT}")
    print(f"  - æ¯ä¸ª source æ¯æ—¥æ‹¼å†™ä¸Šé™: {DAILY_SPELL_LIMIT}")
    print(f"  - æ•°æ®åº“: Supabase PostgreSQL")
    print(f"  - ç­–ç•¥: æŒ‰ source åˆ†ç»„ç‹¬ç«‹åˆ†é…")

    session = get_session()

    try:
        # å…ˆè¿›è¡Œ dry run é¢„è§ˆ
        print("\n" + "=" * 60)
        print("ğŸ” é¢„è§ˆæ¨¡å¼ (ä¸ä¼šä¿®æ”¹æ•°æ®åº“)")
        print("=" * 60)

        redistribute_review_dates(session, dry_run=True)
        redistribute_spell_dates(session, dry_run=True)

        # è¯¢é—®æ˜¯å¦æ‰§è¡Œ
        print("\n" + "=" * 60)
        response = input("æ˜¯å¦æ‰§è¡Œæ›´æ–°? (è¾“å…¥ 'yes' ç¡®è®¤): ")

        if response.lower() == "yes":
            print("\nğŸš€ æ­£åœ¨æ‰§è¡Œæ›´æ–°...")

            # é‡æ–°è·å– session ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
            session.rollback()

            redistribute_review_dates(session, dry_run=False)
            redistribute_spell_dates(session, dry_run=False)

            session.commit()
            print("\nâœ… æ›´æ–°å®Œæˆ!")
        else:
            print("\nâŒ å·²å–æ¶ˆæ“ä½œ")

    except Exception as e:
        session.rollback()
        print(f"\nâŒ é”™è¯¯: {e}")
        raise
    finally:
        session.close()


if __name__ == "__main__":
    main()
